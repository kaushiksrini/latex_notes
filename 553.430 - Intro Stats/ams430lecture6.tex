\classheader{2018-09-19}
\begin{itemize}
	\item Approximation methods, $\Delta$-methods
	\item Ratio estimations
	\item Parametric Estimation
\end{itemize}
Let $X$ be a r.v. mean $\mu_X$ and variance $\sigma_X^2$. Let $g$ be a deterministic function $g: \mathbb{R} \rightarrow \mathbb{R}$. \\
Let $Z = g(X)$ \qquad How to approximate $E[g(X)] = g(Z)$? We could do
\begin{equation*}
	E[Z] \approx g(\mu_X) + \frac{1}{2} g''(\mu_X) \cdot Var(X)
\end{equation*}
Whether or not this approximation is accurate depends on contribution to higher order terms. \\
If $Z = g(X,Y)$, then $E[Z]$ is 
\begin{equation*}
	E[Z] \approx g(\mu_x, \mu_y) + \frac{1}{2} \dfrac{\partial^2 g}{\partial x^2}(\mu_x, \mu_y) \cdot \sigma_X^2 + + \frac{1}{2} \dfrac{\partial^2 g}{\partial y^2}(\mu_x, \mu_y) \cdot \sigma_Y^2 + \dfrac{\partial g}{\partial x \partial y}(\mu_x, \mu_y) \cdot \sigma_{XY}
\end{equation*}
\textbf{Goal:} Understand $E[R]$, $Var(R)$ where $R = \frac{\bar{Y}}{\bar{X}}$ and we are sampling W.o.R from a finite bivariate population\\
\redhline\\\\
Let's consider what happens when $g(X,Y) = \frac{Y}{X}$
\begin{gather*}
	\dfrac{\partial g}{\partial x} = \frac{-y}{x^2} \rightarrow \dfrac{\partial^2 g}{\partial x^2} = \frac{2y}{x^3} \qquad 
	\dfrac{\partial g}{\partial y} = \frac{1}{x} \rightarrow \dfrac{\partial^2 g}{\partial y^2} = 0 \qquad \dfrac{\partial^2 g}{\partial x \partial y} = -\frac{1}{x^2}
\end{gather*}
Here we will look at $g(\bX,\bar{Y}) = \frac{\bX}{\bar{Y}}$ \qquad $E[\bX] = \mu_x$ and $E[\bar{Y}] = \mu_y$
\begin{gather*}
	E[g(\bX,\bar{Y})] = E\bigg[\frac{\bX}{\bar{Y}}\bigg] \approx \frac{\mu_y}{\mu_x} + \frac{1}{2}\bigg(\frac{2 \mu_y}{(\mu_x)^3} \bigg) \sigma_{\bX}^2 + 0 - \frac{1}{\mu_x^2} \sigma_{\bX \bar{Y}}
\end{gather*}
Do we think $\mu_x R$ is unbiased for $\mu_y$ \quad \textbf{Answer: } \underline{No}, it is not unbiased b/c look at approximation
\subsubsection*{What about variance?}
Let's return for a minute on general setting for approximations of moments of functions of random variables. Again $g(X,Y) = Z$\\\\
Let's write 1st order Taylor expansion for $Z$
\begin{gather*}
	Z \approx g(\mu_x, \mu_y) + \dfrac{\partial g}{\partial x}(\mu_x, \mu_y) \cdot (x - \mu_x) + \dfrac{\partial g}{\partial y}(\mu_x, \mu_y) \cdot (y - \mu_y)
\end{gather*}
So we find 
\begin{gather*}
	Z \approx a + b(X - \mu_X) + c(Y - \mu_Y)\\
	Var(Z) \approx b^2Var(X) + c^2 Var(Y) + 2bcCov(X,Y)\\
	\approx \bigg[\underbrace{\dfrac{\partial g}{\partial x}}_{\text{b}} \bigg]^2 \sigma_X^2 + \bigg[\underbrace{\dfrac{\partial g}{\partial y}}_{\text{c}} \bigg]^2 \sigma_Y^2 + 2 \bigg[\underbrace{\dfrac{\partial g}{\partial x}}_{\text{b}} \bigg] \bigg[\underbrace{\dfrac{\partial g}{\partial y}}_{\text{c}} \bigg] \sigma_{XY} 
\end{gather*}
We don't go further than linear as higher variance requires higher order moments e.g. $E[x^4] \leftarrow$ they don't matter.
\begin{gather*}
	Var(R) \approx \bigg[\dfrac{-\mu_y}{\mu_x^2} \bigg]^2 \sigma_{\bX}^2 + \bigg[ \frac{1}{\mu_x} \bigg]^2 \sigma_{\bar{Y}}^2 + 2 \bigg[\dfrac{-\mu_y}{\mu_x^2} \bigg] \bigg[\frac{1}{\mu_x} \bigg] \sigma_{\bX \bar{Y}} \tag{$\star$}
\end{gather*}
Recall
\begin{gather*}
	\sigma_{\bX}^2 = \frac{\sigma_x}{n} \bigg[\frac{N-n}{N-1} \bigg] \qquad \sigma_{\bar{Y}}^2 = \frac{\sigma_y}{n} \bigg[\frac{N-n}{N-1} \bigg]\\
	\sigma_{\bX \bar{Y}} = \circled{?} \quad \frac{\sigma_{xy}}{n} \bigg[\frac{N-n}{N-1} \bigg]
\end{gather*}
Recall
\begin{gather*}
	\sigma_{XY} = \frac{1}{N} \sum_{i=1}^N (x_i - \mu_x)(y_i - \mu_y)\\
	\rho = \frac{\sigma_{xy}}{\sigma_x \sigma_y} \Longrightarrow \boxed{\sigma_{xy} = \rho \sigma_x \sigma_y}
\end{gather*}
Now $\star$ implies
\begin{align*}
	Var(R) & \approx \frac{1}{n} \bigg[\frac{N-n}{N-1}\bigg] \bigg\{ \frac{\mu_y^2}{\mu_x^4} \sigma_x^2 + \frac{1}{\mu_x^2} \sigma_y^2 - \frac{2\mu_y}{\mu_x^3} \sigma_{xy} \bigg\}\\
	& \approx \frac{1}{n\mu_x^2} \bigg[\frac{N-n}{N-1}\bigg] \bigg\{ \underbrace{\frac{\mu_y^2}{\mu_x^2}}_{r^2} \sigma_x^2 + \sigma_y^2 - 2\underbrace{\frac{\mu_y}{\mu_x^3}}_{r} \underbrace{\sigma_{xy}}_{\rho \sigma_x \sigma_y} \bigg\}\\
	Var(R) & \approx \frac{1}{n\mu_x^2} \bigg[\frac{N-n}{N-1}\bigg] \big( r^2\sigma_x^2 + \sigma_y^2 - 2r\rho \sigma_x \sigma_y \big)
\end{align*}
\redhline
\subsection*{Ratio Estimations}
Ratio estimate for $\mu_Y$ is $\mu_X R \leftarrow$ useful if $\mu_X$ is known. We know from before that $E[\mu_X R] \neq \mu_Y$.
\begin{gather*}
	Var(\bar{Y}) = \frac{\sigma_y^2}{n}\bigg[ \frac{N-n}{N-1} \bigg] \hspace{5em} E[\bar{Y}] = \mu 
\end{gather*}
Ratio is useful if bias is small and variance reduction is significant (relative to $Var(\bar{Y})$).\\\\
\underline{Recall}
\begin{align*}
	E(R) & = \frac{\mu_x}{\mu_y} + \frac{1}{\cancel{2}} \frac{\cancel{2} \mu_y}{\mu_x^3} \cdot \frac{\sigma_y^2}{n}\bigg[ \frac{N-n}{N-1} \bigg] - \frac{1}{\mu_X^2} \frac{\sigma_{xy}}{n}\bigg[ \frac{N-n}{N-1} \bigg]\\
	& \approx r + \frac{1}{n \mu_x^2} \bigg[ \frac{N-n}{N-1} \bigg] \big(r\sigma_x^2 - \rho \sigma_x \sigma_y \big)
\end{align*}
Finally,
\begin{align*}
	E[\mu_x R] \approx \mu_y + \frac{1}{\mu_y} \bigg(\frac{1}{n} \bigg) \bigg(\frac{N-n}{N-1} \bigg) (r \sigma_x^2 - \rho \sigma_x \sigma_y)
\end{align*}
So is non-zero, but decaying in $n$.\\ \textbf{Fact: } For $n$ large but small relative to $N$ ($n << N$), $R$ can be approx. using normal distribution.