\classheader{2018-09-05}
Finite Population sampling -- without $i$ without replacement. Mean/expected value and variance of $\bar{X}$\\
Suppose our population is given by $\{x_1, \ldots, x_N\} = \{1,2,2,7,8,9 \}$ where
\begin{center}
	$N = 6$, \quad $x_1 = 1$ \quad $x_2 = 2$\quad $x_3 = 2$ \quad $x_4 = 7$ \quad $x_5 = 8$\quad $x_6 = 9$
\end{center}
Could also describe it by counting.
\begin{center}
	\begin{tabular}{c|c}
		Distinct Value & frequency\\
		\hline
		$\varphi_1 = 1$ & $n_1=1$\\
		$\varphi_2 = 2$ & $n_2=2$\\
		$\varphi_3 = 7$ & $n_3=1$\\
		$\varphi_4 = 8$ & $n_4=1$\\
		$\varphi_5 = 9$ & $n_5=1$\\
	\end{tabular}
\end{center}
Possible sample of size $n=6$, where we sample \underline{without replacement}
\begin{center}
	$X_1 = 7$ \quad $X_2 = 2$ \quad $X_3 = 8$ \quad $X_4 = 9$ \quad $X_5 = 1$ \quad $X_6 = 2$ \quad
\end{center}
Sample here is the same as population as $\circled{n=N}$\\
Same thing \underline{with replacement}
\begin{center}
	$X_1 = 9$ \quad $X_2 = 9$ \quad $X_3 = 9$ \quad $X_4 = 9$ \quad $X_5 = 9$ \quad $X_6 = 9$
\end{center}
Typically $N$ is large and $n << N$\\
Recall population parameters
\begin{equation*}
	\mu = \frac{\sum\limits_{i=1}^{N} X_i}{N} \hspace{5em} \tau = N \mu = \sum\limits_{i=1}^N X_i
\end{equation*}
Next, $\sigma^2$ (population variance)
\begin{equation*}
	\sigma^2 = \frac{1}{N} \sum\limits_{i=1}^N(x_i - \mu)^2 \tag{$\sigma^2$ is pop. variance}
\end{equation*}
Alternatively, we can also express $\sigma^2$ as
\begin{gather*}
	\sigma^2 = \frac{\sum\limits_{i=1}^N(x_i - \mu)^2}{N}  = \frac{\sum\limits_{i=1}^N(x_i^2 - 2\mu x_i + \mu^2)}{N}\\
	= \frac{\sum\limits_{i=1}^N x_i^2}{N} - \frac{2\mu}{N} \underbrace{\sum\limits_{i=1}^Nx_i}_{\mu} + \frac{\cancel{N}\mu^2}{\cancel{N}}\\
	= \frac{\sum\limits_{i=1}^N x_i^2}{N} - 2\mu^2 + \mu^2\\
	= \underbrace{\bigg(\frac{1}{N} \sum\limits_{i=1}^N x_i^2 \bigg)}_{\text{2nd moment}} - \mu^2 = \mu^{(2)} - \mu^2
\end{gather*}
\textbf{Define: } $\mu^{(k)} = \frac{1}{N} \sum\limits_{i=1}^N x_i^k$
\subsection*{Sample Mean $\bar{X}$ as an estimator}
A function of the sample data for the population $\mu$.\\
\emph{Note: } If the sample is random $(X_1, \ldots, X_n \text{ are R.Vs})$, then $\bar{X}$ is \textbf{random!}\\
\underline{Questions:} 
\begin{enumerate}[label=\protect\circled{\arabic*}]
	\item How is $\bar{X}$ distributed? - in theory, if we know $\circled{1}$, then we know the answers $\circled{2}$ \& $\circled{3}$ too.
	\item What is $E[\bar{X}]$?
	\item What is $Var(\bar{X})$?
\end{enumerate}
\underline{\textit{Let's address $\circled{2}$}}\\\\
\qquad Consider $E[\underbrace{X_1}_{\text{\tiny first draw}}]$ \qquad \qquad \hspace{5em} possible values for $X_1 = \{x_1, \ldots, x_N\}$
\begin{equation*}
	P(X_1 = x_k) = \frac{1}{\binom{N}{1}} = \frac{1}{N}
\end{equation*}
\textbf{e.x.} $\{\underbrace{1}_{\tiny x_1},\underbrace{2}_{\tiny x_2},\underbrace{2}_{\tiny x_3},\underbrace{7}_{\tiny x_4},\underbrace{7}_{\tiny x_5},\underbrace{9}_{\tiny x_6} \}$ \hspace{2em} {\scriptsize gives every separate entry a unique ticket even if they are the same}
\begin{equation*}
	E[X_1] = \frac{1}{N} \sum\limits_{k=1}^N x_k = \mu = E[X_2] \tag{b/c $X_1$ \& $X_2$ are identically dist.}
\end{equation*}
In sampling \boxed{\text{without replacement}} $X_i$ \& $X_j$ are \underline{still identically} distributed, but they are \underline{not independent}.\\
In sampling \boxed{\text{with replacement}}, $X_i$ \& $X_j$ are $i.i.d.$\\
Note that whether or not $X_1, \cdots, X_n$ are independent, 
\begin{equation*}
	E\bigg[\sum\limits_{i=1}^N X_i\bigg] = \sum\limits_{i=1}^N E[X_i]
\end{equation*}
\emph{Note:} The sample mean is equal to expected population mean regardless of sampling with or without replacement.
\begin{align*}
	E[\bX] = E\bigg[\frac{1}{n} \sum\limits_{i=1}^n X_i \bigg] = & \frac{1}{n} \sum\limits_{i=1}^N E[X_i]\\
	= & \frac{n\mu}{n} = \mu 
\end{align*}
Since $E[\bX] = \mu$, we say $\bX$ is an \underline{unbiased} estimator for $\mu$. \qquad \textbf{BUT} $\underbrace{\bX}_{\text{\tiny R.V.}} \neq \overbrace{\mu}^{\text{constant}}$\\
\underline{\textit{Let's address $\circled{3}$}}

\subsubsection*{Sampling with replacement.}
\begin{theorem}
	Sampling from finite population with replacement
	\begin{equation*}
		Var(\bX) = \frac{\sigma^2}{n}
	\end{equation*}	
\end{theorem}
\begin{proof}
Here $X_1, \cdots, X_n$ are $i.i.d.$. In general, $X_i$'s are R.V. and $a_i$'s are constants
\begin{equation*}
	Var\big(\sum_i a_i X_i\big) = \sum\limits_i \sum\limits_j a_i a_j cov(X_i, X_j) 
\end{equation*}
If $X_1, \cdots, X_N$ are independent, $\underset{i \neq j}{Cov(X_i, X_j)} = 0$! Hence
\begin{gather*}
	Var(\bX) = Var\bigg(\frac{1}{n} \sum\limits_{i=1}^n X_i \bigg) = \frac{1}{n^2} Var\bigg( \sum\limits_{i=1}^n X_i \bigg) = \frac{1}{n^2}  \sum\limits_{i=1}^n \underbrace{Var(X_i)}_{\text{a constant}}\\
	\boxed{Var(\bX) = \frac{Var(X_i)}{n} = \frac{\sigma^2}{n}}
\end{gather*}
\end{proof}
We need to compute $Var(X_i)$. Observe that $Var(X_i)$ are same for all: \textit{Why?} because they are identical.\\
Also notice $\frac{Var(X_i)}{n}$ decreases with $n$.\\
Observe that for all finite $n$, $Var(\bX)$ is not 0 unless $Var(X_i) = 0$!\\
\emph{Note:} $Var(X_i) = E[(X_i - E(X_i))^2] = E[(X_i - \mu^2)] = \frac{1}{N} \sum (x_i - \mu)^2 = \sigma^2$\\
\underline{So} $Var(X_i) = 0$ \textbf{iff} all $X_i \equiv \mu$
\begin{lemma}
	$bX$ is \underline{consistent} for $\mu$, i.e. $\forall \delta > 0$, the $P(|\bX - \mu| > \delta) \longrightarrow 0$ as $n\rightarrow \infty$
\end{lemma}
For this Lemma, we need to Prove Chebyshev's Inequality, which is
\begin{equation*}
	P(|Z - E(Z)| > \delta) \leq \frac{Var(Z)}{\delta^2}
\end{equation*}
Use this identity!
\begin{gather*}
	E[\bX] = \mu, \hspace{5em} Var(\bX) = \frac{\sigma^2}{n}\\
	P(|\bX - E(\bX)| > \delta) \leq \frac{Var(\bX)}{\delta^2} = \frac{\sigma^2}{n\delta^2} \rightarrow 0 \qquad \text{as } n \rightarrow \infty
\end{gather*}